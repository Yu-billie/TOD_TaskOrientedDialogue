{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad23a68d",
   "metadata": {},
   "source": [
    "### Sarcasm Genertaion based on GPT Augmentation\n",
    "1. 대화 paraphrasing - chatGPT\n",
    "2. sentiment analysis - 공개된 sentiment analysis model [SKIP]\n",
    "3. Sarcasm 생성 - chatGPT\n",
    "    → 마지막 문장에 대해서만 labeling 진행\n",
    "    - 2턴: 7,8\n",
    "    - 4턴: 5,6,7,8\n",
    "    - 6턴: 3,4,5,6,7,8\n",
    "    - 8턴: 1,2,3,4,5,6,7,8\n",
    "- 대화 상황을 요약하는 내용이 생성된 발화에 포함되어서는 안됨 \n",
    "- 대화 참여자가 아닌 제3자의 발언처럼 보이면 안됨\n",
    "- 대화문 길이에 따른 성능 비교: 8, 6, 4, 2 Turn for same files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ebf43",
   "metadata": {},
   "source": [
    "#### env set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed4b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set GPU env  \n",
    "import torch \n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) \n",
    "dtype = torch.FloatTensor \n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# Current Directory check\n",
    "import os             \n",
    "os.getcwd()     \n",
    "dpath = '/home/work/CUAI6th_1/YuminKim/messenger_files/'\n",
    "get_files = os.listdir(dpath) \n",
    "\n",
    "# !pip install openai \n",
    "import openai\n",
    "import random\n",
    "from transformers import pipeline\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163af2fa",
   "metadata": {},
   "source": [
    "#### read json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef373571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MMRW1900000372.json ('어쩌다 가게되써', '그냥 별거 없어 국내랑 다를게 없는데.....ㅎㅎ', 'ㅋㅋㅋㅋㅋㅋㅋ내가 집돌이라 그런걸수도 있겠다', 'ㅋㅋㅋㅋㅋ 으으 좀 나가라 넌 ㅋㅋㅋ돌아댕겨야지', '헤헤...개춥...존춥...', '추울때는 동남아가 최고야 ㅠㅠㅠ나 택배 아져씨와서ㅠㅠㅠㅠㅠㅠ이따 얘기하쟈', 'ㅋㅋㅋㅋㅋㅋ언넝 맞이해')\n",
      "(1, 'MMRW1900000372.json') sarcasm:\n",
      "동남아에서 추울 때는 따뜻한 편인가봐. 택배 아저씨랑 얘기하려니까 너무 기대되네. 좋은 이야기 해줄게, 정말로!\n"
     ]
    }
   ],
   "source": [
    "conv_length = 8\n",
    "limit = conv_length - 1  \n",
    "\n",
    "import json \n",
    "no=1\n",
    "\n",
    "with open(dpath+'MDRW1900000002.json', 'r') as file:\n",
    "    speaker_order, line_list = [], []\n",
    "    data = json.load(file)\n",
    "    utterance = data['document'][0]['utterance']\n",
    "    turns = int(utterance[-1]['id'].split('.')[-1])  # total numbers of turns \n",
    "    for i in range(turns):\n",
    "        speaker_order.append(utterance[i]['speaker_id'])\n",
    "        line_list.append(utterance[i]['form'])\n",
    "\n",
    "\n",
    "# print(speaker_list, conv_list)\n",
    "dialog = dict(zip(conv_list, speaker_order))   \n",
    "# print(len(speaker_list), len(conv_list))\n",
    "\n",
    "# Last N-Turn conversation \n",
    "turn, length_back = 1, 1             \n",
    "for i in range(2,len(dialog)):    \n",
    "    if turn >= limit:               \n",
    "        break  \n",
    "    elif speaker_order[-i] == speaker_order[-i+1]:        \n",
    "        turn += 0   \n",
    "        length_back += 1 \n",
    "    elif speaker_order[-i] != speaker_order[-i+1]:   \n",
    "        turn += 1   \n",
    "        length_back += 1          \n",
    "\n",
    "conv = line_list[len(speaker_order)-length_back : ]\n",
    "\n",
    "# split based on continous speaker --> user, assistant  \n",
    "speaker_inconv = speaker_order[len(speaker_order)-length_back :]  \n",
    "\n",
    "continuous = split_conv(speaker_inconv)   \n",
    "conv1_length, conv2_length, conv3_length, conv4_length, conv5_length, conv6_length  = continuous[0], continuous[1], continuous[2], continuous[3], continuous[4], continuous[5]\n",
    "conv1 = ''.join(conv[:conv1_length][:])\n",
    "conv2 = ''.join(conv[conv1_length: conv1_length+conv2_length])\n",
    "conv3 = ''.join(conv[conv1_length+conv2_length : conv1_length+conv2_length+conv3_length])\n",
    "conv4 = ''.join(conv[conv1_length+conv2_length+conv3_length: conv1_length+conv2_length+conv3_length+conv4_length])\n",
    "conv5 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length: conv1_length+conv2_length+conv3_length+conv4_length+conv5_length])\n",
    "conv6 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length+conv5_length : conv1_length+conv2_length+conv3_length+conv4_length+conv5_length+conv6_length])\n",
    "conv7 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length+conv5_length+conv6_length: ])\n",
    "org = conv1,conv2, conv3, conv4, conv5, conv6, conv7  \n",
    "\n",
    "# paraphrased = paraphrase(''.join(org_conv[:]))\n",
    "sarc_generated = sarcasm_generation(conv1, conv2, conv3, conv4, conv5, conv6) # generate sarcasm without paraphrasing  \n",
    "\n",
    "# print(f'{no,filename} paraphrased:\\n{paraphrased}')             \n",
    "print(no,filename,org)      \n",
    "print(f'{no,filename} sarcasm:\\n{sarc_generated}')      \n",
    "\n",
    "# # lst = [no, filename, \n",
    "# # # paraphrased, \n",
    "# # sarc_generated]  # merge paraphrasing + generated sarcasm   \n",
    "# # result.append(lst)  # making dataframe to extract in xlsx file \n",
    "\n",
    "# # no+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ba8852a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "누나 모해??\n",
      "ㅋㅋㅋㅋ 일하고 있지ㅠㅠ\n",
      "ㅋㅋㅋㅋㅋㅋ나돈데 지금 몰래 여행갈곳 찾는중 ㅎ\n",
      "오오 어디?\n",
      "외국은 돈이 없어서 못가구 ㅠ\n",
      "국내에서 온천?갈까 생각중이야\n",
      "국내에 온천이 있어?\n",
      "찾아보니까 온양온천???있던데?\n",
      "역도 있더라 ㄷㄷ\n",
      "ㅋㅋㅋㅋ헐 대박 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ 어때?\n",
      "쫌 괜춘한거 같긴한데 아직 알아보는중이라 ㅠㅠ\n",
      "누나는 어디 안가?\n",
      "나는 연말에 휴가 있어서 그때 해외로 뜰거야 ㅎㅎ\n",
      "오 해외오디???\n",
      "방콕갔다올라고 ㅋㅋㅋ 예전에 가서 카운트다운했는데 너무 재밌게 놀았어서 한번 더 가서 할라구><\n",
      "오..방콕이....베트남인가...?태국인가?\n",
      "태국이지 ㅋㅋㅋㅋㅋ 베트남은 호치민?\n",
      "아맞네맞네 ㅋㅋㅋㅋㅋ 잠깐 헷갈렷당\n",
      "나도 국내말고 해와가고싶다...\n",
      "나좀데려가조.....\n",
      "캐리어에 넣어줄까..?\n",
      "ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      "베트남은 나랑 안맞아서 태국이 좋아 ㅠㅠ\n",
      "베트남 알레르기...?\n",
      "태국만 벌써 두번 갔다 왔는데 이번에 가면 세번째지롱\n",
      "오\n",
      "모야\n",
      "부러워\n",
      "나 해외\n",
      "나간적 한번두 없는데\n",
      "너 누나 세계여행 하고 온거 몰라?\n",
      "ㅋㅋㅋㅋㅋㅋ진짜로??????\n",
      "작년에 8개월 나갔다왔자나 ㅎㅎ\n",
      "진짜???어디어디????\n",
      "17개국인가 18개국 갔다왔어\n",
      "와.....왠일로????\n",
      "누나가 직접?\n",
      "아니면 뭐 패키지같은거야??\n",
      "볼리비아 페루 콜롬비아 베네수엘라 멕시코 쿠바 프랑스 영국 아이슬란드 포루투칼 스페인 모로코 이집트 요르단\n",
      "아니 배낭여행 ㅋㅋㅋㅋㅋㅋ\n",
      "혼자서?!??!\n",
      "와 뭔가 부럽다...ㅠㅠ\n",
      "웅ㅋㅋㅋㅋㅋ 공항이랑 버스터미널에서 자면서\n",
      "여행했쥐\n",
      "나는 엄두도 못내겠던데....\n",
      "진짜 신기하다 ㅋㅋㅋㅋㅋ나랑 뭔가 다른세계사람같앜ㅋㅋㅋㅋㅋ\n",
      "지금까지 갔다온 나라 다합하면 30개국 될걸?\n",
      "앞으로 여행문의는 주지혜투어?\n",
      "예전에 한번 세어보니까 30개국에 100개 도시 넘게 갔다왔는데\n",
      "앜ㅋㅋㅋㅋㅋㅋㅋㅋ\n",
      "티켓팅은 알아서^^\n",
      "ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ나는\n",
      "뭔가 해외여행갈라치면\n",
      "여권부터시작해서 짐싸고 뭐하고 알아보고\n",
      "이런게 눔 ㄱ ㅣ찮아서 ㅠㅠ\n",
      "차마...못하겟어....\n",
      "누나처럼 장시간 여행가려면 하던것도\n",
      "ㅋㅋㅋㅋㅋㅋ\n",
      "다 손놓고 가야해서 ㅠ\n",
      "어쩌다 가게되써\n",
      "그냥 별거 없어 국내랑 다를게 없는데.....ㅎㅎ\n",
      "ㅋㅋㅋㅋㅋㅋㅋ내가 집돌이라 그런걸수도 있겠다\n",
      "ㅋㅋㅋㅋㅋ 으으 좀 나가라 넌 ㅋㅋㅋ\n",
      "돌아댕겨야지\n",
      "헤헤...개춥...존춥...\n",
      "추울때는 동남아가 최고야 ㅠㅠㅠ\n",
      "나 택배 아져씨와서\n",
      "ㅠㅠㅠㅠㅠㅠ\n",
      "이따 얘기하쟈\n",
      "ㅋㅋㅋㅋㅋㅋ언넝 맞이해\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(line_list)):\n",
    "    print(line_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c221da6",
   "metadata": {},
   "source": [
    "#### Sarcasm Generation and Paraphrasing\n",
    "- Sarcasm Generation \n",
    "    1. speaker tagging \n",
    "    2. input conversation in `User`, `Assistnant` role, NOT in the prompt  \n",
    "    3. COT(Chain-of-Thought): generate the reason of sarcasm firstly, and then generate sarcasm sentence \n",
    "    4. generate {`sarcasm`, `non_sarcasm`} pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc51ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_no = [116, 275, 342, 534, 600, 775, 921, 1075, 1103, 1366, 1375, 1657, 1946, 2229, 2327, 2407, 2421, 2465, 2889, 2952, 2995, 3000, 3233, 3297, 3335, 3426, 3520, 3927, 3955, 4071, 4228, 4424, 4547, 4703, 4801, 4834, 5235, 5440, 5475, 5806, 5818, 5996, 6017, 6259, 6351, 6416, 6517, 6548, 6897, 7048, 7249, 7833, 8368, 8628, 8837, 9007, 9368, 9611, 9702, 9829, 9880, 10171, 10290, 10948, 11067, 11203, 11385, 11727, 11759, 11869, 11939, 12102, 12675, 12711, 12750, 13010, 13080, 13179, 13422, 13818, 13851, 14258, 14791, 14875, 15127, 15649, 15868, 15890, 15998, 16444, 16444, 16493, 16710, 16745, 16874, 17009, 17597, 17736, 17869, 17880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e20988",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_length = 8\n",
    "limit = conv_length - 1  \n",
    "no=100  # experiment number       \n",
    "result = []\n",
    "\n",
    "for filename in get_files:\n",
    "    # for experiment in range(98,100):\n",
    "    # if filename == get_files[read_no[experiment]]:\n",
    "    if filename == get_files[read_no[-1]]:    \n",
    "        filepath = os.path.join(dpath, filename)\n",
    "        with open(filepath, encoding=\"utf-8\") as f:\n",
    "            speaker_order = [] \n",
    "            line_list = []\n",
    "            org_line = []\n",
    "            while True:     \n",
    "                line = f.readline().strip()  \n",
    "                if not line: \n",
    "                    break      \n",
    "                str_line = ''.join([str(item) for item in line]).replace('키키', '') # list -> string to delete certain word '키키' \n",
    "                str_line = ''.join([str(item) for item in str_line]).replace('하하', '') # list -> string to delete certain word '하하' \n",
    "                str_line = ''.join([str(item) for item in str_line]).replace('ㅋ', '') # list -> string to delete certain word 'ㅋ' \n",
    "                str_line = ''.join([str(item) for item in str_line]).replace('ㅠㅠ', '...') # list -> string to change certain word 'ㅠㅠ' for express sentiment  \n",
    "                \n",
    "                speaker_order.append(int(str_line[:2]))   # save speaker \n",
    "                line_list.append(str_line[4:])            # save conversation   \n",
    "                org_line.append(str_line[:])\n",
    "\n",
    "            dialog = dict(zip(line_list, speaker_order))  # dialog = {text line : speaker}  \n",
    "\n",
    "            # Last N-Turn conversation \n",
    "            turn, length_back = 1, 1             \n",
    "            for i in range(2,len(dialog)):    \n",
    "                if turn >= limit:               \n",
    "                    break  \n",
    "                elif speaker_order[-i] == speaker_order[-i+1]:        \n",
    "                    turn += 0   \n",
    "                    length_back += 1 \n",
    "                elif speaker_order[-i] != speaker_order[-i+1]:   \n",
    "                    turn += 1   \n",
    "                    length_back += 1          \n",
    "\n",
    "            conv = line_list[len(speaker_order)-length_back : ]   \n",
    "\n",
    "            # split based on continous speaker --> user, assistant  \n",
    "            speaker_inconv = speaker_order[len(speaker_order)-length_back :]  \n",
    "\n",
    "            \n",
    "            continuous = split_conv(speaker_inconv)   \n",
    "            conv1_length, conv2_length, conv3_length, conv4_length, conv5_length, conv6_length  = continuous[0], continuous[1], continuous[2], continuous[3], continuous[4], continuous[5]\n",
    "            conv1 = ''.join(conv[:conv1_length][:])\n",
    "            conv2 = ''.join(conv[conv1_length: conv1_length+conv2_length])\n",
    "            conv3 = ''.join(conv[conv1_length+conv2_length : conv1_length+conv2_length+conv3_length])\n",
    "            conv4 = ''.join(conv[conv1_length+conv2_length+conv3_length: conv1_length+conv2_length+conv3_length+conv4_length])\n",
    "            conv5 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length: conv1_length+conv2_length+conv3_length+conv4_length+conv5_length])\n",
    "            conv6 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length+conv5_length : conv1_length+conv2_length+conv3_length+conv4_length+conv5_length+conv6_length])\n",
    "            conv7 = ''.join(conv[conv1_length+conv2_length+conv3_length+conv4_length+conv5_length+conv6_length: ])\n",
    "            org_conv = org_line[len(speaker_order)-length_back :]\n",
    "            print(org_conv)\n",
    "            \n",
    "            # paraphrased = paraphrase(''.join(org_conv[:]))\n",
    "            sarc_generated = sarcasm_generation(conv1, conv2, conv3, conv4, conv5, conv6) # generate sarcasm without paraphrasing  \n",
    "            \n",
    "            # print(f'{no,filename} paraphrased:\\n{paraphrased}')             \n",
    "            print(f'{no,filename} sarcasm:\\n{sarc_generated}')      \n",
    "            \n",
    "            lst = [no, filename, org_conv,\n",
    "            # paraphrased, \n",
    "            sarc_generated]  # merge paraphrasing + generated sarcasm   \n",
    "            result.append(lst)  # making dataframe to extract in xlsx file \n",
    "\n",
    "            no+=1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23f1f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarcasm_generation(conv1, conv2, conv3, conv4, conv5, conv6):   \n",
    "    content = ''       \n",
    "    prompt = f\"\"\"   \n",
    "    '계란프라이가 바싹 타버렸어.' \n",
    "    '[sarcasm] 이거 정말 바삭바삭하겠는걸. (실제로 계란프라이가 바싹 타서 먹을 수 없는 상황을 비꼬는 속마음을 강조하기 위해 오히려 바삭바삭하다고 칭찬하는 것처럼 말하는 반어법 형태)\n",
    "     [non_sarcasm] 다 타버려서 못 먹는 계란프라이라니 정말 최악이다. (계란프라이가 바싹 타서 먹을 수 없는 상황에 대한 직설적이고 솔직한 대답)'      \n",
    "     \"\"\"        \n",
    "\n",
    "    messages = [  \n",
    "            {'role': 'system', 'content': '너는 재밌게 비꼬는 대답[sarcasm]과 직설적이고 솔직한 대답[non_sarcasm] 동시에 모두 말해주는 영리한 한국인 친구야. 너의 대답은 한구어 반어법 연구에 큰 도움이 될테니 최대한 비꼬는 형식으로 대답해줘. 그리고 상반된 예문을 위해 직설적이고 솔직한 대답도 같이 해줘.'},\n",
    "            \n",
    "            # COT + {sarcasm, non_sarcasm} pairs \n",
    "            {'role': 'user', 'content': '계란프라이가 바싹 타버렸어.'},      \n",
    "            {'role': 'assistant', 'content': '[sarcasm] 이거 정말 바삭바삭하겠는걸. (실제로 계란프라이가 바싹 타서 먹을 수 없는 상황을 비꼬는 속마음을 강조하기 위해 오히려 바삭바삭하다고 칭찬하는 것처럼 말하는 반어법 형태)\\n[non_sarcasm] 다 타버린 계란프라이라니 정말 최악이다. (계란프라이가 바싹 타서 먹을 수 없는 상황에 대한 직설적이고 솔직한 대답)'},               \n",
    "\n",
    "            # input conversation [6 Turn] \n",
    "            # {'role': 'user', 'content': conv1},\n",
    "            {'role': 'assistant', 'content': conv1},\n",
    "            {'role': 'user', 'content': conv2},\n",
    "            {'role': 'assistant', 'content': conv3},\n",
    "            {'role': 'user', 'content': conv4},   \n",
    "            {'role': 'assistant', 'content': conv5},\n",
    "            {'role': 'user', 'content': conv6},   \n",
    "             ]    \n",
    "    # print(conv1,'\\n', conv2,'\\n', conv3,'\\n', conv4,'\\n', conv5,'\\n', conv6,'\\n', conv7)\n",
    "    response = openai.ChatCompletion.create(  \n",
    "        model='gpt-3.5-turbo-16k',   # 16,384 tokens\n",
    "        messages=messages  )\n",
    "\n",
    "    sarc_sentence = (str(response['choices'][0]['message']['content']))    \n",
    "    reply = sarc_sentence.splitlines()   \n",
    "\n",
    "    return '\\n'.join(reply)    # print in string NOT in list formation      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b222c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금지 사항: \n",
    "# 1.비관적이면 안 돼 (DO NOT be pessimistic!)\n",
    "# 2.입력된 대화문에서 부정적으로 생각하는 요소가 있다면, 생성할 대답에서는 그 부정적 요인을 반복해서 언급하지 마.  \n",
    "# 3.입력된 대화에 부정적인 요인이 있을 경우 대답에는 그것에 대한 긍정적인 요인만 생각하여 긍정적인 대답으로 생성해줘. \n",
    "\n",
    "# 입력 예시2: '1: 너 오늘 야근이야! 너 오늘 밤에 잠 못 잘거야.'  (야근 = 부정적 요인)\n",
    "# 출력 예시2: '2: 내일 컨디션 최고겠다~' (컨디션 최고 = 부정적 요인에 대한 거짓된 긍정적 표현으로, 컨디션이 나쁠 것이라는 내재된 의미 강조) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f12984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(text):    \n",
    "\n",
    "    content = ''\n",
    "    # prompt = f'입력된 대화문을 한국어로 parphrasing 해줘. {text}'      \n",
    "    \n",
    "    messages = [\n",
    "            {'role': 'system', 'content': '너는 입력된 대화문의 의미를 유지하면서 한국어로 paraphrasing 하는 한국인 친구야.'},\n",
    "            {'role': 'user', 'content': text},\n",
    "        ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages,\n",
    "        # temperature = 0.5\n",
    "        )\n",
    "\n",
    "    paraphrased = (str(response['choices'][0]['message']['content']).strip())\n",
    "\n",
    "    return paraphrased   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dcbf0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker_inconv = [1,1,1, 2, 1,1]\n",
    "def split_conv(speaker_inconv): \n",
    "    result = []\n",
    "    count = 1\n",
    "    for i in range(1, len(speaker_inconv)):\n",
    "        if speaker_inconv[i] == speaker_inconv[i-1]: \n",
    "            count += 1\n",
    "        else:\n",
    "            result.append(count)\n",
    "            count = 1\n",
    "    result.append(count)\n",
    "    return result\n",
    "\n",
    "# continuous = split_conv(speaker_inconv)\n",
    "# conv1_length, conv2_length, conv3_length = continuous[0], continuous[1], continuous[2]\n",
    "# conv1 = speaker_inconv[:conv1_length]\n",
    "# conv2 = speaker_inconv[conv1_length: conv1_length+conv2_length]\n",
    "# conv3 = speaker_inconv[conv1_length+conv2_length: ]\n",
    "\n",
    "# print(conv1, conv2, conv3)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accedf42",
   "metadata": {},
   "source": [
    "### result txt file --> xlsx file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "433f5a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/tmp/ipykernel_643611/494388251.py:13: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# !pip install xlsxwriter\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xlsxwriter \n",
    "\n",
    "result1 = \n",
    "result = np.concatenate((result1, result2))\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "writer = pd.ExcelWriter('8turn_100.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='8turn', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a95e73",
   "metadata": {},
   "source": [
    "### MEMO\n",
    "ChatGPT fine-tuning: to increasing generation performance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5207281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_no = []\n",
    "# for i in range(100):\n",
    "#     read_no.append(random.randrange(0, 18000))\n",
    "# read_no = sorted(read_no)\n",
    "# print(read_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List --> string \n",
    "ls =  ['2 : 좋아하면 하나 사 주던지 ', '1 : 아 근데 맨날 그것만 누르고 공부를 안 해서', '2 : 공부할 때는 엄마한테 잠깐 맡겨 놓으라고 해', '1 : 친구 거 빌려서 해 봤는데 하루종일 그것만 누르고 있더라고', '2 : 그러면 안 되지...', '2 : 집중할 때는 집중해야지', '1 : 그래서 사주는게 좀 망설여지네', '2 : 온라인에 많이 있으니 아들이랑 미리 이야기 해보고 하나 사줘']\n",
    "''.join(ls[:])  \n",
    "'\\n'.join(ls[:]) # enter for every line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ff1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 API code \n",
    "import requests\n",
    "import json\n",
    "\n",
    "API_KEY = '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'\n",
    "# API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "def generate_chat_completion(messages, model=\"gpt-4\", temperature=1, max_tokens=None):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\", \n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }   \n",
    "\n",
    "    if max_tokens is not None:\n",
    "        data[\"max_tokens\"] = max_tokens\n",
    "\n",
    "    response = requests.post(API_ENDPOINT, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Translate the following English text to French: 'Hello, how are you?'\"}\n",
    "]\n",
    "\n",
    "response_text = generate_chat_completion(messages)\n",
    "print(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
